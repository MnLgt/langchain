{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20deed05",
   "metadata": {},
   "source": [
    "# Unstructured File Loader\n",
    "This notebook covers how to use Unstructured to load files of many types. Unstructured currently supports loading of text files, powerpoints, html, pdfs, images, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2886982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Install package\n",
    "# !pip install \"unstructured[local-inference]\"\n",
    "# !pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2\"\n",
    "# !pip install layoutparser[layoutmodels,tesseract]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d62efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install other dependencies\n",
    "# # https://github.com/Unstructured-IO/unstructured/blob/main/docs/source/installing.rst\n",
    "# !brew install libmagic\n",
    "# !brew install poppler\n",
    "# !brew install tesseract\n",
    "# # If parsing xml / html documents:\n",
    "# !brew install libxml2\n",
    "# !brew install libxslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a64f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d3e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "import os \n",
    "from apikey import apikey \n",
    "\n",
    "import streamlit as st \n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain \n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.utilities import WikipediaAPIWrapper \n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50728a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = apikey\n",
    "\n",
    "\n",
    "loader = TextLoader('email.txt', encoding='utf8')\n",
    "loader2 =  TextLoader('email2.txt', encoding='utf8')\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "index = VectorstoreIndexCreator().from_loaders([loader, loader2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544785cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What was Yuyen's excuse for why his company used the music without a license?\"\n",
    "response = index.query(query, verbose=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de9ef16",
   "metadata": {},
   "source": [
    "## PDF Example\n",
    "\n",
    "Processing PDF documents works exactly the same way. Unstructured detects the file type and extracts the same types of `elements`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08390401",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\"chavinlo/alpaca-native\")\n",
    "\n",
    "base_model = LlamaForCausalLM.from_pretrained(\n",
    "    \"chavinlo/alpaca-native\",\n",
    "    load_in_8bit=True,\n",
    "    device_map='auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686e5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader # for loading the pdf\n",
    "# from langchain.embeddings import OpenAIEmbeddings # for creating embeddings\n",
    "from langchain.embeddings import LlamaCppEmbeddings\n",
    "\n",
    "from langchain.vectorstores import Chroma # for the vectorization part\n",
    "from langchain.chains import ChatVectorDBChain # for chatting with the pdf\n",
    "# from langchain.llms import OpenAI # the LLM model we'll use (CHatGPT)\n",
    "from langchain.llms import LlamaCpp\n",
    "\n",
    "pdf_path = '/Users/jordandavis/Downloads/jonas.pdf'\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load_and_split()\n",
    "print(pages[0].page_content[:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64684b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Users/jordandavis/dalai/alpaca/models/7B/ggml-model-q4_0.bin'\n",
    "\n",
    "model = LlamaCpp(model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = OpenAIEmbeddings()\n",
    "embeddings = LlamaCppEmbeddings(model_path=model_path)\n",
    "vectordb = Chroma.from_documents(pages, embedding=embeddings, persist_directory=\".\")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_qa = ChatVectorDBChain.from_llm(model,\n",
    "                                    vectordb, return_source_documents=True)\n",
    "\n",
    "query = \"Where are the workers going?\"\n",
    "result = pdf_qa({\"question\": query, \"chat_history\": \"\"})\n",
    "print(\"Answer:\")\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b1f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
